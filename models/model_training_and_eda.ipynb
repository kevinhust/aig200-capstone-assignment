{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SleepInsight AI - Model Training & EDA\n",
                "\n",
                "This notebook documents the exploratory data analysis and model training process for the SleepInsight AI project using the unified training dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error, r2_score\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "%matplotlib inline\n",
                "sns.set_theme(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "\n",
                "We load the processed training data which combines features from multiple sources."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('../data/processed_training_data.csv')\n",
                "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Exploratory Data Analysis (EDA)\n",
                "\n",
                "Visualizing the relationships between features and the target `sleep_score`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.histplot(df['sleep_score'], bins=20, kde=True, color='teal')\n",
                "plt.title('Distribution of Sleep Scores')\n",
                "plt.show()\n",
                "\n",
                "plt.figure(figsize=(12, 8))\n",
                "numeric_df = df.select_dtypes(include=[np.number])\n",
                "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
                "plt.title('Feature Correlation Matrix')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Training\n",
                "\n",
                "We use a `RandomForestRegressor` within a scikit-learn pipeline for robust preprocessing and prediction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df.drop('sleep_score', axis=1)\n",
                "y = df['sleep_score']\n",
                "\n",
                "numeric_features = ['age', 'sleep_duration_hr', 'heart_rate', 'stress_level', 'rem_percent', 'deep_percent', 'awakenings']\n",
                "categorical_features = ['gender']\n",
                "\n",
                "numeric_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='mean')),\n",
                "    ('scaler', StandardScaler())\n",
                "])\n",
                "\n",
                "categorical_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
                "])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numeric_transformer, numeric_features),\n",
                "        ('cat', categorical_transformer, categorical_features)\n",
                "    ])\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "model_pipeline = Pipeline(steps=[\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
                "])\n",
                "\n",
                "print(\"Training model...\")\n",
                "model_pipeline.fit(X_train, y_train)\n",
                "\n",
                "y_pred = model_pipeline.predict(X_test)\n",
                "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
                "print(f\"R2 Score: {r2_score(y_test, y_pred):.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "importances = model_pipeline.named_steps['regressor'].feature_importances_\n",
                "feature_names = numeric_features + list(model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features))\n",
                "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "feat_imp.plot(kind='barh', color='skyblue')\n",
                "plt.title('Feature Importance')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model for deployment\n",
                "joblib.dump(model_pipeline, 'sleep_model_pipeline.pkl')\n",
                "print(\"Model artifact updated at models/sleep_model_pipeline.pkl\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}